# The Lexer Object
# ----------------
# Reads a string of Coco code and divvies it up into tagged tokens.
# Tokens are in the form:
#
#     ['TAG', 'value', lineNumber = 0]
#
# which is a format that can be fed directly into
# [Jison](http://github.com/zaach/jison) generated [parser](../lib/parser.js).
# Some potential ambiguity in the grammar has been avoided by
# pushing some extra smarts into Lexer.

sax = require 'sax'

`
String.prototype.replace_all = function(f, r) {
  var  str = this,
      i = str.indexOf(f),
      inc = f.indexOf(r),
      len;

  if(i !== -1) {
    inc = inc === -1 ? 0 : inc+1;
    len = f.length;
    do {
      str = str.substr(0, i) + r + str.substr(i + len);

      i = str.indexOf(f, i + inc);
    } while(i !== -1);
  }

  return str;
}
`
exports import
  # `lex` is Lexer's one and only public method.
  lex: (
    # Coco source to be parsed into an array of tokens.
    code
    #  - `.raw`  <br> Suppresses [rewriting](#rewriter) if truthy.
    #  - `.line` <br> Specifies the starting line. Defaults to `0`.
    options
  # `tokenize` is Lexer's main method. Scan by attempting to match tokens
  # one at a time, using a regular expression anchored at the start of the
  # remaining code, or a custom recursive token-matching method
  # (for interpolations). When the next token has been recorded,
  # we move forward within the code past the token, and begin again.
  ) -> (^exports)tokenize code||'' options||{}
  tokenize: (code, o) ->
    @inter or code.=replace /\r/g ''
    # Prepend a newline to handle leading INDENT.
    code = \\n + code
    # Stream of parsed tokens,
    # initialized with a TERMINATOR token to ensure `@last` always exists.
    @tokens = [@last = [\TERMINATOR \\n 0]]
    # The current line. Starts from -1 to setoff the prepended newline.
    @line = ~-o.line
    # The stack of all current indentation levels.
    @dents = []
    # The stack for pairing tokens.
    @closes = []
    # The stack for tagging parameters.
    @parens = []
    # Call tokenizers based on the character at current `i`ndex.
    # Each tokenizing method is responsible for
    # returning the number of characters it has consumed.
    i = 0
    while c = code.charAt i
      switch c
      case ' '   then i += @doSpace     code, i
      case \\n   then i += @doLine      code, i
      case \\    then i += @doBackslash code, i
      case \' \" then i += @doString    code, i, c
      case \/
        switch code.charAt i+1
        case \* then i += @doComment code, i
        case \/ then i += @doHeregex code, i
        default      i += @doRegex code, i or @doLiteral code, i
      case \` then i += @doJS code, i
      default
        c2 = code.charAt i+1
        if c is \< and (\a <= c2 <= \z or \A <= c2 <= \Z)
          i += @doTags code, i
        else
          i += @doIdentifier code, i or @doNumber code, i
            or @doLiteral    code, i or @doSpace  code, i
    # Close up all remaining open blocks.
    @dedent @dent
    @carp "missing `#that`" if @closes.pop()
    if @inter
    then @rest? or @carp 'unterminated interpolation'
    else @last.spaced = true; @newline()
    # Rewrite the token stream unless explicitly asked not to.
    o.raw or @rewrite!
    @tokens

  # The current indentation level.
  dent: 0

  #### Tokenizers

  # Matches an identifying literal: variables, keywords, accessors, etc.
  doIdentifier: (code, ID.lastIndex) ->
    return 0 unless input = (match = ID.exec code)0
    [, id, colon] = match; {last} = this
    # `id:_` `_.id` `@id`
    if colon or last.0 is \DOT or @adi()
      tag = \ID
      (id = new String id)reserved = true if id of KEYWORDS
    # keywords
    else switch id
    case <[ this eval ]> then return @token(\LITERAL id, true)length
    case <[ true false null void arguments debugger ]> then tag = \LITERAL
    case \new \do \typeof \delete then tag = \UNARY
    case \return \throw           then tag = \HURL
    case \break  \continue        then tag = \JUMP
    case \for  then @seenFor = true; fallthrough
    case \then then @seenFrom = @seenTo = false
    case \catch    then @unterminate(); fallthrough
    case \function then id = ''
    case \else \case \default \finally then @unterminate()
    case <[ in of instanceof ]>
      if id is not \instanceof and @seenFor
        @seenFor = false
        # OF holds the index variable.
        if id is \of
          id = ''; @seenTo = true
          if last.0 is \ID then switch @tokens[*-2]0
          case \,    then @tokens.splice -2 1; fallthrough
          case \} \] then @tokens.pop(); id = last.1
        break
      if last.1 is \!
        @tokens.pop()
        id = \! + id
      tag = \RELATION
    case <[ and or is not ]>
      if id is \not and last.alias and last.1 is \===
      then last.1 = \!==
      else @token ...COCO_ALIASES[id]; @last.alias = true
      return id.length
    case \unless then tag = \IF
    case \until  then tag = \WHILE
    case \import
      id = \<<<
      able @tokens or @token \LITERAL \this
    default
      break if id of KEYWORDS_SHARED
      @carp "reserved word \"#id\"" if id of KEYWORDS_UNUSED
      if not last.1 and last.0 of <[ CATCH FUNCTION LABEL ]>
        return (last.1 = id)length
      tag = \ID
      # contextual keywords (reserved only in specific places)
      switch id
      case \own then tag = \OWN if last.0 is \FOR
      case \all then if last.1 is \<<<
        last.1 += \<
        return 3
      case \from then if @tokens[*-2]?0 is \FOR
        import {-seenFor, +seenFrom}
        tag = \FROM
      case \to \til
        if @seenFrom
        or @tokens[*-2]?0 is \FOR and (@token \FROM ''; @token \STRNUM \0)
          import {-seenFrom, +seenTo}
          tag = \TO
        else if last.0 is \STRNUM and not last.callable
          last <<< 0:\RANGE op:id
          return id.length
      case \by
        if last.0 is \STRNUM and @tokens[*-2]0 is \RANGE
        then tag = \RANGE_BY
        else @seenTo &&= !tag = \BY
      case \ever then if last.0 is \FOR
        @seenFor = false; last.0 = \WHILE; tag = \LITERAL; id = \true
    @token tag || match.1.toUpperCase(), id
    @token \: \: if colon
    input.length

  # Matches a number, including decimal, hex and exponential notation.
  doNumber: (code, NUMBER.lastIndex) ->
    return 0 unless input = (match = NUMBER.exec code)0
    {last} = this
    # `. 0.0` => `. 0 . 0`
    if match.5 and (last.0 is \DOT or @adi!)
      @token \STRNUM match.4.replace NUMBER_OMIT, ''
      return match.4.length
    if radix = match.1
      num = parseInt rnum = match.2.replace(NUMBER_OMIT, ''), radix
      if isNaN num or num is parseInt rnum.slice(0 -1), radix
        @carp "invalid number #rnum in base #radix"
      num += ''
    else
      num = (match.3 or input)replace NUMBER_OMIT, ''
      if match.3 and num.charAt! is \0 and num.charAt(1) not of ['' \.]
        @carp "deprecated octal literal #{match.4}"
    if not last.spaced and last.0 is \+-
      last.0 = \STRNUM; last.1 += num
      return input.length
    @strnum num
    input.length

  # Matches a string literal.
  doString: (code, index, q) ->
    if q is code.charAt index+1
      return if q is code.charAt index+2
      then @doHeredoc code, index, q
      else @strnum q+q; 2
    if q is \"
      parts = @interpolate code, index, q
      @addInterpolated parts, unlines
      return 1 + parts.size
    [str] = (SIMPLESTR <<< lastIndex: index)exec code
    str or @carp 'unterminated string'
    @strnum unlines string q, str.slice 1 -1
    @countLines(str)length

  # Matches a tag literal.
  doTags: (code, index, q) ->
    xml_func = 'cE' #TODO: make this customizable
    parse = true
    attributes = 0
    parser = sax.parser true
    depth = 0
    scopes = [[]];
    idx = index
    add_scope = (token, opts) ->
      if !token then return
      scopes[depth].push token
      last = scopes[depth].length-1
      if opts and opts.code
        if scopes[depth].code_start >= 0
          scopes[depth].code_blocks.push last
          scopes[depth].code_end = last
        else
          scopes[depth].code_blocks = [last]
          scopes[depth].code_start = last

    parser.onopentag = (node) ->
      #console.log 'open', node
      attributes = []
      for k, v in node.attributes
        switch k
        case 'class' then k = 'c'
        case 'for' then k = 'f'
        attributes.push [\ID, k], [':', ':']
        attributes.push [\STRNUM, if isNaN v*1 then '"""'+v.trim!+'"""' else String v]
        attributes.push [',', ',']
      
      attributes.pop!
      tokens = []
      tokens.push [\ID, xml_func], [\CALL(, '(', callable: true], [\STRNUM, "'#{node.name}'"], [',', ',']
      if attributes.length
        tokens.push ['{', '{']
        for a of attributes then tokens.push a
        tokens.push ['}', '}']
      else
        tokens.push [\STRNUM, 0]
        
      add_scope {tokens: tokens}
      if typeof scopes[++depth] is not \array
        scopes[depth] = []

    parser.onclosetag = (node) ->
      #console.log 'close', node
      depth--
      prev = scopes[depth][*-1]
      scope = scopes[depth+1]
      if scope.length
        if scope.code_start >= 0
          if isNaN scope.code_end
            throw new Error "unterminated code scope"
          else
            code_start = scope.code_start
            code_end = scope.code_end
            #scope[code_start] = "function(){var o=[];#{scope[code_start]}"
            scope[code_start].unshift {tokens: [[\UNARY, \do], [\PARAM, '('], [\ID, 'o'], [')PARAM', ') ->'], [\INDENT, 1], [\ID, 'o'], [\ASSIGN, '= []'], [\TERMINATOR, '\n']]}
            code_scope = scope.splice code_start+1, code_end-code_start
            for v, i of code_scope
              if i is code_scope.length-1
                #scope[code_start] += "#{v};return o}()"
                scope[code_start].push {tokens: [v, [\HURL, 'return'], [\ID, 'o']]}
              else if scope.code_blocks.indexOf(i) is not -1
                #scope[code_start] += "o.push(#{v});"
                scope[code_start].push {tokens: [v, [\ID, 'o'], [\DOT, '.'], [\ID, \push], ['CALL(', '('], v, [')CALL', ')'], [\TERMINATOR, '\n']]}
              else
                #scope[code_start] += v
                scope[code_start].push v
        for s of scope
          prev.tokens.push [',', ','], s
        
      #OPTIMIZE: if previous tokens are ',' and '0' then remove them
      scopes[depth+1] = []
      scopes[depth].push {tokens: [[')CALL', ')CALL']]}
      if depth is 0 then parser.end!

    parser.ontext = (text) ~>
      text = String text
      if isNaN text*1
        add_scope [\STRNUM, '"""'+text.trim!+'"""']
      else
        add_scope [\STRNUM, text]

    parser.onprocessinginstruction = (node) ->
      console.log 'code', node
      /*
      switch node.name
      case '=' then add_scope node.body.trim!g
      default then add_scope node.body.trim!, {code: 1}
      */

    parser.onend = ~>
      parse := 0
      tokens = scopes[0]
      i = 0
      while i < tokens.length
        s = tokens[i]
        if s.tokens then tokens.splice.apply tokens, [i, 1].concat s.tokens
        else i++
      for t of tokens
        if t.0 is \STRNUM and t.1.substr(0, 3) is '"""' then @doHeredoc t.1, 0, '"'
        else @token.apply @, t
    
    len = @tokens.length
    while parse is true
      c = code.charAt idx++
      parser.write c
    idx - index
    

  # Matches heredocs, adjusting indentation to the correct level,
  # as they ignore indentation to the left.
  doHeredoc: (code, index, q) ->
    if q is \'
      ~(end = code.indexOf q+q+q, index+3) or @carp 'unterminated heredoc'
      raw = code.slice index+3 end
      # Remove trailing indent.
      doc = raw.replace LASTDENT, ''
      @strnum enlines string q, lchomp detab doc, heretabs doc
      return @countLines(raw)length + 6
    parts = @interpolate code, index, q+q+q
    tabs  = heretabs code.slice(index+3 index+parts.size)replace LASTDENT, ''
    for t, i of parts then if t.0 is \S
      t.1.=replace LASTDENT, '' if i+1 is parts.length
      t.1 = detab t.1, tabs
      t.1 = lchomp t.1 if i is 0
    @addInterpolated parts, enlines
    3 + parts.size

  # Matches block comments.
  doComment: (code, index) ->
    comment = if ~end = code.indexOf \*/ index+2
    then code.slice index, end+2
    else code.slice(index) + \*/
    if @last.0 of <[ TERMINATOR INDENT THEN ]>
    then @token \COMMENT detab comment, @dent; @token \TERMINATOR \\n
    else @last.spaced = true
    @countLines(comment)length

  # Matches embedded JavaScript.
  doJS: (code, JSTOKEN.lastIndex) ->
    [js] = JSTOKEN.exec code
    js or @carp 'unterminated JS literal'
    @js detab js.slice(1 -1), @dent
    @countLines(js)length

  # Matches a regular expression literal aka _regex_,
  # disambiguating from division operators.
  doRegex: (code, index) ->
    # To coexist with implicit call and ACI,
    # disallow leading space or equal sign when applicable.
    #
    #     f /re/ 9 /ex/   # f(/re/, 9, /ex/)
    #     a /= b / c / d  # division
    #
    if divisable = able @tokens
      return 0 if not @last.spaced or code.charAt(index+1) of [' ' \=]
    [input, body, flag] = (REGEX <<< lastIndex: index)exec code
    if input
    then @regex body, flag
    else divisable or @carp 'unterminated regex'
    input.length

  # Matches a multiline, extended regex literal.
  doHeregex: (code, index) ->
    {tokens, last} = this
    parts = @interpolate code, index, \//
    rest  = code.slice index + 2 + parts.size
    flag  = @validate /^(?:[gimy]{1,4}|[?$]?)/exec(rest)0
    if parts.1
      if flag is \$
        @adi(); @token \( \"
      else
        tokens.push [\ID \RegExp last.2] [\CALL( '' last.2]
        if flag is \?
          for t, i of parts by -1 then if t.0 is \TOKENS
            dynaflag = parts.splice(i, 1).0.1
            break
      for t, i of parts
        if t.0 is \TOKENS
          tokens.push ...t.1
        else
          val = t.1.replace HEREGEX_OMIT, ''
          continue if one and not val
          one = tokens.push t <<< [\STRNUM string \' enslash val]
        tokens.push [\+- \+ tokens[*-1]2]
      tokens.pop()
      if dynaflag or flag >= \g
        @token \, \,
        if dynaflag then tokens.push ...dynaflag else @token \STRNUM "'#flag'"
      @token (if flag is \$ then \) else \)CALL), ''
    else @regex reslash(parts.0.1.replace HEREGEX_OMIT, ''), flag
    2 + parts.size + flag.length

  # Matches a word literal, or ignores a sequence of whitespaces.
  doBackslash: (code, BSTOKEN.lastIndex) ->
    [input, word] = BSTOKEN.exec code
    if word then @strnum string \' word else @countLines input
    input.length

  # Matches newlines and {in,de}dents, determining which is which.
  # If we can detect that the current line is continued onto the next line,
  # then the newline is suppressed:
  #
  #     elements
  #     .map -> ...
  #     .get()
  #
  # Keeps track of the level of indentation, because a single dedent
  # can close multiple indents, so we need to know how far in we happen to be.
  doLine: (code, index) ->
    [input, tabs] = (MULTIDENT <<< lastIndex: index)exec code
    {length} = @countLines input
    {last} = this; last <<< {+eol, +spaced}
    return length if index + length >= code.length
    if 0 > delta = tabs.length - @dent
      @dedent -delta
      LINE_CONTINUER.test code.slice index+1 or @newline()
    else
      if tabs and (@emender ||= //[^#{ tabs.charAt 0 }]//)exec tabs
        @carp "contaminated indent #{ escape that }"
      if (tag = last.0) is \ASSIGN and ''+last.1 not of <[ = := += ]>
      or tag of <[ +- DOT LOGIC MATH COMPARE RELATION SHIFT BITWISE
                   IN OF TO BY FROM ]>
        return length
      cont = LINE_CONTINUER.test code.slice index+1
      if delta then @indent delta, cont else cont or @newline()
    @seenFrom = @seenTo = false
    length

  # Consumes non-newline whitespaces and/or a line comment.
  doSpace: (code, SPACE.lastIndex) ->
    @last.spaced = true if input = SPACE.exec(code)0
    input.length

  # We treat all other single characters as a token. e.g.: `( ) , . !`
  # Multi-character operators are also literal tokens, so that Jison can assign
  # the proper order of operations. There are some symbols that we tag specially
  # here. `;` and newlines are both treated as a TERMINATOR, we distinguish
  # parentheses that indicate a method call from regular parentheses, and so on.
  doLiteral: (code, index) ->
    return 0 unless sym = (SYMBOL <<< lastIndex: index)exec(code)0
    switch tag = val = sym
    case \. \?.       then tag = \DOT
    case \+ \-        then tag = \+-
    case \&& \||      then tag = \LOGIC
    case \?  \!?      then tag = \LOGIC if @last.spaced
    case \/ \% \**    then tag = \MATH
    case \++ \--      then tag = \CREMENT
    case \<<< \<<<<   then tag = \IMPORT
    case \& \|        then tag = \BITWISE
    case \;           then tag = \TERMINATOR
    case <[ === !== < > <= >= == != ]> then tag = \COMPARE
    case <[  <<  >>  >>>    <?  >?  ]> then tag = \SHIFT
    case \(
      unless @last.0 of <[ FUNCTION LET ]> or @able true
        @token \( \(
        @closes.push \)
        @parens.push @last
        return 1
      tag = \CALL(
      @closes.push \)CALL
    case \[ \{
      @adi()
      @closes.push ']}'charAt val is \{
    case \}
      if @inter and val is not @closes[*-1]
        @rest = code.slice index+1
        return 9e9
      fallthrough
    case \] \)
      @lpar = @parens.pop! if \) is tag = val = @pair val
    case \: then if @last.0 not of <[ ID STRNUM ) ]>
      tag = \LABEL; val = ''
    case <[ = := += -= *= /= %= &= ^= |= <<= >>= >>>= <?= >?= **= ]>
      tag = \ASSIGN
      if @last.0 is \LOGIC
        (val = new String val)logic = @tokens.pop()1
      else if @last.1 of <[ . ?. ]> or @last.0 is \? and @adi()
        @last.1 += val
        return val.length
    case \*
      if @last.0 of <[ TERMINATOR INDENT THEN ]> and
         /^.[^\n\S]*(?=\S)/exec code.slice index
        @tokens.push [\{ \{ @line] [\} \} @line] [\ASSIGN \= @line]
        @indent val = that.0.length
        return val
      tag = if able @tokens then \MATH else \STRNUM
    case \@ \@@
      @dotcat val or if val is \@
      then @token \LITERAL \this true
      else @token \LITERAL \arguments
      return val.length
    case \!
      :CONTACT unless @last.spaced
        if able @tokens, null true
          @token \CALL( ''; @token \)CALL \!
        else if @last.1 is \typeof
          @last.1 = \classof
        else break CONTACT
        return 1
      tag = \UNARY
    case \~
      return 1 if @dotcat val
      tag = \UNARY
    case \~> then tag = \->; fallthrough
    case \-> then @parameters! or (@token \PARAM( ''; @token \)PARAM '')
    case \<~ then tag = \<-; fallthrough
    case \<-
      break if @parameters!
      {tokens} = this; i = tokens.length
      continue until tokens[--i]0 of <[ TERMINATOR INDENT THEN ( ]>
      tokens.splice i+1 0 [\PARAM( '' tokens[i]2]
      @token \)PARAM ''
    case \:: then i = \prototype; fallthrough
    case \.. then @adi(); tag = \ID; val = i || \constructor
    default switch val.charAt 0
    case \( then @token \CALL( \(; tag = \)CALL; val = \)
    case \<
      @carp 'unterminated words' if val.length < 4
      @adi!; tag = \WORDS; val.=slice 2 -2
    @token tag, val
    sym.length

  #### Token Manipulators

  # Records an INDENT.
  indent: (delta, dummy) ->
    @dent += delta
    @dents.push if dummy then ''+delta else @token \INDENT delta
    @closes.push \DEDENT
    void

  # Records a DEDENT, or DEDENTs if there are multiple matching INDENTs.
  dedent: (debt) ->
    @dent -= debt
    while debt > 0 and dent = @dents.pop()
      if debt < dent and not @inter
        @carp "unmatched dedent (#debt for #dent)"
      @pair \DEDENT
      debt -= if typeof dent is \number then @token \DEDENT dent else dent
    void

  # Generates a newline token. Consecutive newlines get merged together.
  newline: -> @token \TERMINATOR \\n unless @last.1 is \\n; void

  # Removes the last token if TERMINATOR.
  unterminate: -> @tokens.length -= @last.0 is \TERMINATOR; void

  # Re-tags function parameters.
  parameters: -> @last.1 is \) and (@lpar.0 = \PARAM(; @last.0 = \)PARAM)

  # Expands variables and expressions inside double-quoted strings or heregexes
  # using Ruby-like notation for substitution of arbitrary expressions.
  #
  #     "Hello #{name.capitalize()}."
  #
  # Will recursively create a new lexer for each interpolation,
  # tokenizing the contents and merging them into the token stream.
  interpolate: (str, idx, end) ->
    parts = []; end0 = end.charAt 0; pos = 0; i = -1
    str.=slice idx + end.length
    while ch = str.charAt ++i
      switch ch
      case end0
        continue unless end is str.slice i, i + end.length
        parts.push [\S; @countLines str.slice 0 i; @line]
        return parts <<< size: pos + i + end.length
      case \#
        if id = (ID <<< lastIndex: i+1)exec(str)1
          break if id is \this or id not of KEYWORDS
          i += id.length
          continue
        continue unless \{ is str.charAt i+1
      case \\ then ++i; fallthrough
      default continue
      # `"#a#{b || c}"` => `a + "" + (b || c)`
      if i or nested and not stringified
        stringified = parts.push [\S; @countLines str.slice 0 i; @line]
      if id
        str.=slice delta = i + 1 + id.length
        parts.push [\TOKENS nested = [[\ID id, @line]]]
      else
        clone  = ^exports <<< {+inter, @emender}
        nested = clone.tokenize str.slice(i+2), {@line, +raw}
        nested.shift() while nested.0?0 is \TERMINATOR
        @countLines str.slice i, delta = str.length - clone.rest.length
        str = clone.rest
        if nested.length
          nested.unshift [\( \( nested.0.2]
          nested.push    [\) \) @line]
          parts.push [\TOKENS nested]
      pos += delta; i = -1
    @carp "missing `#end`"; void

  # Merges `@interpolate`d strings.
  addInterpolated: (parts, nlines) ->
    return @strnum nlines string \" parts.0.1 unless parts.1
    @adi()
    {tokens, last} = this
    tokens.push [\( \" last.2]
    for t, i of parts
      if t.0 is \TOKENS
        tokens.push ...t.1
      else
        continue if i > 1 and not t.1
        tokens.push [\STRNUM; nlines string \" t.1; t.2]
      tokens.push [\+- \+ tokens[*-1]2]
    tokens.pop()
    @token \) '' last.0 is \DOT

  #### Helpers

  # Adds a token to the results,
  # taking note of the line number and returning `value`.
  token: (tag, value, callable) ->
    @tokens.push @last = [tag, value, @line]
    @last.callable = true if callable
    value

  # Records a string/number token, supplying implicit dot if applicable.
  strnum: -> @token \STRNUM it, @adi() || @last.0 is \DOT; void

  # Records a literal token flagged embedded.
  js: -> @token \LITERAL new String(it) <<< {+js}

  # Records a regex token.
  regex: (body, flag) ->
    try RegExp body catch @carp e.message
    return @strnum string \' enslash body if flag is \$
    @js "/#{ body or '(?:)' }/#{ @validate flag }"

  # Complains on duplicate flag.
  validate: (flag) ->
    if flag and /(.).*\1/exec flag
      @carp "duplicate regex flag `#{that.1}`"
    flag

  # Increments `@line` by the number of newlines in a string.
  countLines: -> ++@line while pos = 1 + it.indexOf \\n pos; it

  # Checks if the last token is
  #
  # - `f()`: `call`able via explicit parentheses
  # - `x''`: indexable via implicit brackets
  able: (call) -> not @last.spaced and able @tokens, null call

  # Supplies an implicit DOT if applicable.
  adi: ->
    not @last.spaced and if @last.0 is \?
    then @last <<< [\DOT \?.]
    else able @tokens and @token \DOT \.

  # Resolves `.~` etc.
  dotcat: -> @last.1 += it if @last.1 of <[ . ?. ]> or @adi()

  # Pairs up a closing token.
  pair: ->
    unless it is (wanted = @closes[*-1]) or \)CALL is wanted and it is \)
      @carp "unmatched `#it`" unless \DEDENT is wanted
      # Auto-close DEDENT to support code like:
      #
      #     [ a
      #       b ]
      #
      @dedent @dents[*-1]
      return @pair it
    @unterminate()
    @closes.pop()

  # Throws a syntax error with the current line number.
  carp: -> carp it, @line

  # Rewrites the token stream in multiple passes, one logical filter at a time.
  # The order of these passes matters--indentation must be
  # corrected before implicit parentheses can be wrapped around blocks of code.
  rewrite: ->
    it ||= @tokens
    addImplicitIndentation it
    tagPostfixConditionals it
    addImplicitParentheses it
    addImplicitBraces      it
    expandLiterals         it
    it.shift! if it.0?0 is \TERMINATOR
    it

#### Helpers

function carp msg, lno then throw SyntaxError "#msg on line #{-~lno}"

# Checks whether or not the previous token is {index,`call`}able.
function able tokens, i ? tokens.length, call
  [tag] = token = tokens[i-1]
  tag of <[ ID ] SUPER ]> or if call
  then token.callable or tag is \? or tag of <[ ) )CALL ]> and token.1
  else tag of <[ } ) )CALL STRNUM LITERAL WORDS ]>

#### String Manipulators

# Constructs a string literal by (un)escaping quotes and newlines.
string = let do
  escaped = /\\(?:[\\0-7bfnrtuvx]|[^\n\S]|([\w\W]))?/g
  descape = ($0, $1) -> $1 or if $0 is \\ then \\\\ else $0
  qs = "'":/'/g '"':/"/g
then (q, body) -> q + body.replace(escaped, descape)replace(qs[q], \\\$&) + q

# Detects the minimum indent count for a heredoc, ignoring empty lines.
function heretabs doc
  dent = 0/0
  dent <?= that.0.length - 1 while TABS.exec doc
  dent
TABS = /\n[^\n\S]*(?!$)/mg

# Erases all external indentations up to specified length.
function detab str, len
  if len then str.replace detab[len]||=//\n[^\n\S]{1,#len}//g \\n else str

# Erases all newlines and indentations.
function unlines then it.replace INDENTS, ''
INDENTS = /\n[^\n\S]*/g

# Converts newlines/backslashes to their quoted form.
function enlines then it.replace LINES, \\\n
LINES = /\n/g

function enslash then it.replace BACKSLASHES, \\\\
BACKSLASHES = /\\/g

# Quotes slashes unless already quoted.
reslash = let re = /(\\.)|\//g, fn = (-> @@1 or \\\/) then -> it.replace re, fn

# Deletes the first character if newline.
function lchomp then it.slice 1 + it.lastIndexOf \\n 0

function decode val, lno
  return [+val] unless isNaN val
  val = if val.length > 8 then \ng else do Function \return + val
  val.length is 1 or carp 'bad string in range' lno
  [val.charCodeAt!, true]

function uxxxx then \"\\u + (\000 + it.toString 16)slice(-4) + \"
character = if JSON!? then uxxxx else ->
  switch it case 0x2028 0x2029 then uxxxx it
  default JSON.stringify String.fromCharCode it

#### Rewriters

# The Coco language has a good deal of optional syntax, implicit syntax,
# and shorthand syntax. This can greatly complicate a grammar and bloat
# the resulting parse table. Instead of making the parser handle it all,
# we take a series of passes over the token stream, using this **Rewriter**
# to convert shorthand into the unambiguous long form, add implicit indentation
# and parentheses, and generally clean things up.

# Tag postfix conditionals as such, so that we can parse them with a
# different precedence.
function tagPostfixConditionals tokens
  detectEnd tokens, i+1, ok, go if token.0 is \IF for token, i of tokens
  function ok then it.0 of <[ TERMINATOR INDENT ]>
  function go then it.0 is \INDENT and (it.1 or it.then) or token.0 = \POST_IF
  void

# Because our grammar is LALR(1), it can't handle some single-line
# expressions that lack ending delimiters. **Rewriter** adds the implicit
# blocks, so it doesn't need to. `)` can close a single-line block,
# but we need to make sure it's balanced.
function addImplicitIndentation tokens
  i = 0
  while token = tokens[++i]
    [tag] = token
    continue unless tag of <[ THEN -> ELSE DEFAULT TRY CATCH FINALLY ]>
    switch next = tokens[i+1]0
    case \IF then continue if tag is \ELSE
    case \INDENT \THEN
      tokens.splice i-- 1 if tag is \THEN
      continue
    indent = [\INDENT 0 token.2]; dedent = [\DEDENT 0]
    if tag is \THEN
      tokens.splice --i, 1 if tokens[i-1]0 is \TERMINATOR
      (tokens[i] = indent)then = true
    else
      tokens.splice ++i, 0 indent
    switch
    # ->,
    case next of <[ , DOT ]> then --i; fallthrough
    # -> 0,
    case next of <[ ID STRNUM LITERAL SUPER ]> and \, is tokens[i+2]?0
      go 0 i+=2; ++i
    # -> [0],
    case next of <[ ( [ { ]>
     and \, is tokens[idx = 1 + indexOfPair tokens, i+1]?0
      go 0 idx; ++i
    default
      seenSwitch = false
      detectEnd tokens, i+1, ok, go
  function ok token, i
    switch token.0
    case \DEDENT        then true
    case \TERMINATOR    then token.1 is not \;
    case \, \DOT        then tokens[i-1]eol
    case \ELSE          then tag is \THEN
    case \CATCH         then tag is \TRY
    case \FINALLY       then tag of <[ TRY CATCH THEN ]>
    case \SWITCH        then not seenSwitch := true
    case \CASE \DEFAULT then not seenSwitch
  function go [] i
    prev = tokens[i-1]
    tokens.splice if prev.0 is \, then i-1 else i, 0, dedent <<< {prev.2}
  void

# Functions may be optionally called without parentheses for simple cases.
# Insert the missing parentheses here to aid the parser.
function addImplicitParentheses tokens
  i = 0; brackets = []
  while token = tokens[++i]
    doblock = false
    if token.1 is \do and tokens[i+1]?0 is \INDENT
      endi = indexOfPair tokens, i+1
      if tokens[endi+1]0 is \TERMINATOR and tokens[endi+2]?0 is \WHILE
        token.0 = \DO
        tokens[endi+2]done = true
        tokens.splice endi+1 1
      else
        (token = tokens[1+ i])0 = \(
        (tpair = tokens[endi])0 = \)
        doblock = tokens.splice i, 1
    [tag] = token; prev = tokens[i-1]
    brackets.push prev.0 is \DOT if tag is \[
    if prev.0 is \]
      if brackets.pop() then prev.index = true else continue
    unless prev.0 of <[ FUNCTION LET ]>
      continue unless prev.spaced and able tokens, i, true
    if doblock
      token.0 = \CALL(; tpair.0 = \)CALL
      continue
    continue unless tag of ARG or not token.spaced and tag of <[ +- ^ ]>
    if tag is \CREMENT
      continue if token.spaced or tokens[i+1]?0 not of CHAIN
    skipBlock = seenSwitch = false
    tokens.splice i++, 0 [\CALL( '' token.2]
    detectEnd tokens, i, ok, go
  function ok token, i
    return true if not skipBlock and token.alias and token.1 of <[ && || ]>
    pre = tokens[i-1]
    switch token.0
    case \DOT then return not skipBlock and (pre.spaced or pre.0 is \DEDENT)
    case \SWITCH                         then seenSwitch := true; fallthrough
    case \IF \CLASS \FUNCTION \LET \WITH then skipBlock  := true
    case \CASE
      if seenSwitch then skipBlock := true else return true
    case \INDENT
      return skipBlock := false if skipBlock
      return pre.0 not of <[
        { [ , -> : ELSE ASSIGN IMPORT UNARY DEFAULT TRY CATCH FINALLY HURL DO
      ]>
    case \WHILE
      return false if token.done
      fallthrough
    case <[ TERMINATOR POST_IF FOR BY TO ]>
      return pre.0 is not \,
    false
  function go token, i then tokens.splice i, 0 [\)CALL '' tokens[i-1]2]
  void

# Object literals may be written without braces for simple cases.
# Insert the missing braces here to aid the parser.
function addImplicitBraces tokens
  stack = []; i = 0
  while token = tokens[++i]
    unless \: is tag = token.0
      switch
      case tag of CLOSERS then start = stack.pop()
      case tag of OPENERS
        tag = \{ if tag is \INDENT and tokens[i-1]0 is \{
        stack.push [tag, i]
      continue
    paren   = tokens[i-1]0 is \)
    oneline = paren and tokens[start.1 - 1]?0 is \: or # a: (..):
              tokens[i-2]?0 is \:                      # a: b:
    continue unless oneline or stack[*-1]?0 is not \{
    stack.push [\{]
    idx  = if paren then start.1 else i-1
    idx -= 2 while tokens[idx-2]?0 is \COMMENT
    tokens.splice idx, 0 [\{ \{ token.2]
    detectEnd tokens, ++i+1, ok, go
  function ok token, i
    return true if token.1 is \; or \DEDENT is tag = token.0
    switch tag
    case \,          then break
    case \TERMINATOR then return true if oneline
    default return false
    t1 = tokens[i+1]?0
    t1 is not (if tag is \, then \TERMINATOR else \COMMENT) and
    \: is not tokens[if t1 is \( then 1 + indexOfPair tokens, i+1 else i+2]?0
  function go token, i then tokens.splice i, 0 [\} '' token.2]
  void

# - Slip unary {pl,min}uses off signed numbers.
# - Expand ranges and words.
# - Insert `void` before empty commas.
# - Insert `()` after each `function`/`let` facing a block.
# - Insert `, ` after each non-callable token facing an argument token.
function expandLiterals tokens
  i = 0
  while token = tokens[++i]
    switch token.0
    case \STRNUM
      if ~'-+'indexOf sig = token.1.charAt 0
        token.1.=slice 1
        tokens.splice i++ 0 [\+- sig, token.2]
      continue if token.callable
    case \RANGE
      [from, char] = decode token.1, lno = token.2
      [to, tochar] = decode tokens[i+1]1, lno
      carp 'bad "to" in range' if char ^ tochar
      if by = tokens[i+2]?0 is \RANGE_BY
        carp 'bad "by" in range' if isNaN by = tokens[i+3]?1
      ts = []; to -= token.op is \til and 1e-15
      for n from from to to by +by or 1
        carp 'range limit exceeded' lno if 0x10000 < ts.push \
          [\STRNUM, if char then character n else "#n", lno] [\, \, lno]
      if ts.length then ts.pop() else carp 'empty range' lno
      tokens.splice i, if by then 4 else 2, ...ts
      i += ts.length - 1
    case \WORDS
      ts = [[\[ \[ lno = token.2]]
      for word of token.1.match /\S+/g or ''
        ts.push [\STRNUM; string \' word; lno] [\, \, lno]
      tokens.splice i, 1, ...ts, [\] \] lno]
      i += ts.length
    case \,
      if tokens[i-1]0 of <[ , [ CALL( PARAM( ]>
        tokens.splice i++ 0 [\LITERAL \void token.2]
      continue
    case \INDENT
      if tokens[i-1]
        if that.1 is \new
          tokens.splice i++ 0 \
            [\PARAM( '' token.2] [\)PARAM '' token.2] [\-> '' token.2]
        else if that.0 of <[ FUNCTION LET ]>
          tokens.splice i, 0 [\CALL( '' token.2] [\)CALL '' token.2]
          i += 2
      continue
    case \LITERAL \} \!? then break
    case \) \)CALL then continue if token.1
    case \]        then continue if token.index
    case \CREMENT  then continue unless able tokens, i
    default continue
    if token.spaced and tokens[i+1]0 of ARG
      tokens.splice ++i, 0 [\, \, token.2]
  void

# Seeks `tokens` from `i`ndex and `go` for a token of the same level
# that's `ok` or an unmatched closer.
function detectEnd tokens, i, ok, go
  levels = 0
  while token = tokens[i], ++i
    return go token, i if not levels and ok token, i
    [tag] = token
    return go token, i if 0 > levels += tag of OPENERS or -(tag of CLOSERS)
  void

function indexOfPair tokens, i
  level = 1; end = INVERSES[start = tokens[i]0]
  while tokens[++i]
    switch that.0
    case start then ++level
    case end   then return i unless --level
  -1

#### Constants

##### Keywords

# Keywords that Coco shares in common with JavaScript.
KEYWORDS_SHARED = <[
  true false null this void super return throw break continue
  if else for while switch case default try catch finally class extends
  new do delete typeof in instanceof import function let with debugger
]>

# The list of keywords that are reserved by JavaScript, but not used.
# We throw a syntax error for these to avoid runtime errors.
KEYWORDS_UNUSED = <[ var  const enum export   implements interface
                     package private protected public static yield ]>

KEYWORDS = KEYWORDS_SHARED.concat KEYWORDS_UNUSED

# Coco-only alias keywords.
COCO_ALIASES  = not: <[ UNARY !  ]>, is: <[ COMPARE === ]>
              , and: <[ LOGIC && ]>, or: <[ LOGIC   ||  ]>

##### Regexes
# Some of these are given `g` flag and made sure to match empty string
# so that they can lex from any index by receiving `.lastIndex` beforehand.

ID = //
  ( [$A-Za-z_\x7f-\uffff][$\w\x7f-\uffff]* )
  ( [^\n\S]* : (?![:=]) )?  # Is this a property name?
|//g
SYMBOL = //
  [-+*/%&|^:<>]=              # compound assign / comparison
| \.{1,3}                     # dot / `constructor` / splat/placeholder/yada*3
| ([+&|:])\1                  # increment / logic / `prototype`
| \([^\n\S]*\)                # call
| -[->]                       # decrement / function
| [!=]==?                     # equality
| \?\.                        # soak access
| ~[.>]                       # bind access/function
| @@                          # `arguments`
| <\[(?:[\s\S]*?\]>)?         # words
| <(?: <(?:=|<{0,2}) | [-~])  # left shift / import / backcall
| >>>?=?                      # rite shift
| [<>]\?=?                    # min/max
| !\?                         # inexistence
| \*\*=?                      # pow
| [^\s#]?
//g
SPACE     = /(?=.)[^\n\S]*(?:#.*)?|/g
MULTIDENT = /(?:\s*#.*)*(?:\n([^\n\S]*))+/g
SIMPLESTR = /'[^\\']*(?:\\[\s\S][^\\']*)*'|/g
JSTOKEN   = /`[^\\`]*(?:\\[\s\S][^\\`]*)*`|/g
BSTOKEN   = // \\ (?: (\S[^\s,;)}\]]*) | \s* ) //g

NUMBER = //
  0x[\da-f][\da-f_]*                                      # hex
| ([2-9]|[12]\d|3[0-6]) r ([\da-z][\da-z_]*)              # 2-36 base
| ( (\d[\d_]*)(\.\d[\d_]*)? (?:e[+-]?\d[\d_]*)? ) [a-z_]* # decimal
|//ig
NUMBER_OMIT = /_+/g

REGEX = //
  /( [^ [ / \n \\ ]*                              # every other thing
     (?: (?: \\.                                  # anything escaped
           | \[ [^\]\n\\]* (?:\\.[^\]\n\\]*)* \]  # or character class
         ) [^ [ / \n \\ ]*                        # every other thing again
     )*
  )/ ([gimy]{1,4}|\$?)
|//g
HEREGEX_OMIT = /\s+(?:#.*)?/g

LASTDENT = /\n[^\n\S]*$/

LINE_CONTINUER = // ^ \s* (?
: [,&|>%] | \.(?!\.) | <(?![-~[]) | !?\?
| (?:and|or)(?![$\w\x7f-\uffff]|[^\n\S]*:(?![:=]))
) //

##### Tokens

# Tokens that signal the start/end of a balanced pair.
OPENERS = <[ ( [ { CALL( PARAM( INDENT ]>
CLOSERS = <[ ) ] } )CALL )PARAM DEDENT ]>

# The inverse mappings of {OPEN,CLOS}ERS to look things up from either end.
INVERSES = new -> import {(c = CLOSERS[i]): o, (o): c} for o, i of OPENERS

# Tokens that can start a dot/call chain.
CHAIN = <[ ( { [ ID STRNUM LITERAL LET WITH WORDS ]>

# Tokens that can start an argument list.
ARG = CHAIN.concat <[ ... UNARY CREMENT PARAM( FUNCTION
                      IF SWITCH TRY CLASS SUPER RANGE LABEL DO ]>
